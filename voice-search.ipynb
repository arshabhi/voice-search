{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d854f83",
   "metadata": {},
   "source": [
    "## Loading Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9b6b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:24.475631Z",
     "start_time": "2023-10-02T13:10:23.822893Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e43ed6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:25.187680Z",
     "start_time": "2023-10-02T13:10:24.478643Z"
    }
   },
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc274991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:25.193134Z",
     "start_time": "2023-10-02T13:10:25.190214Z"
    }
   },
   "outputs": [],
   "source": [
    "# to remove warnings for unverified requests\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "# to remove warnings in Jupyter Notebook \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4f2ead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:34.517912Z",
     "start_time": "2023-10-02T13:10:25.195641Z"
    }
   },
   "outputs": [],
   "source": [
    "# mainly for checking the language and removing non-english language\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1f9995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:34.568135Z",
     "start_time": "2023-10-02T13:10:34.520013Z"
    }
   },
   "outputs": [],
   "source": [
    "# record audio imports\n",
    "\n",
    "import wave\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import tkinter as tk\n",
    "import pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a54abbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:34.592847Z",
     "start_time": "2023-10-02T13:10:34.569966Z"
    }
   },
   "outputs": [],
   "source": [
    "# open AI init\n",
    "\n",
    "import openai\n",
    "openai.api_key = \"<your-open-ai-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4afad0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## page crawl/get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1a3759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:35.939813Z",
     "start_time": "2023-10-02T13:10:34.594798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "\n",
    "from urllib.parse import urlsplit\n",
    "def get_domain(text):\n",
    "    return (urlsplit(text).netloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ef5bbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:36.024196Z",
     "start_time": "2023-10-02T13:10:35.945058Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>If you’ve ever found yourself looking up the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>Machine learning is increasingly moving from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gant Laborde</td>\n",
       "      <td>1.3K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>If your understanding of A.I. and Machine Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emmanuel Ameisen</td>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
       "      <td>Want to learn about applied Artificial Intelli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author claps reading_time  \\\n",
       "0        Justin Lee  8.3K           11   \n",
       "1       Conor Dewey  1.4K            7   \n",
       "2  William Koehrsen  2.8K           11   \n",
       "3      Gant Laborde  1.3K            7   \n",
       "4  Emmanuel Ameisen   935           11   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1  https://towardsdatascience.com/python-for-data...   \n",
       "2  https://towardsdatascience.com/automated-featu...   \n",
       "3  https://medium.freecodecamp.org/machine-learni...   \n",
       "4  https://blog.insightdatascience.com/reinforcem...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chatbots were the next big thing: what happene...   \n",
       "1  Python for Data Science: 8 Concepts You May Ha...   \n",
       "2  Automated Feature Engineering in Python – Towa...   \n",
       "3  Machine Learning: how to go from Zero to Hero ...   \n",
       "4  Reinforcement Learning from scratch – Insight ...   \n",
       "\n",
       "                                                text  \n",
       "0  Oh, how the headlines blared:\\nChatbots were T...  \n",
       "1  If you’ve ever found yourself looking up the s...  \n",
       "2  Machine learning is increasingly moving from h...  \n",
       "3  If your understanding of A.I. and Machine Lear...  \n",
       "4  Want to learn about applied Artificial Intelli...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/articles.csv\", dtype=str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f70f8d92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:36.035182Z",
     "start_time": "2023-10-02T13:10:36.027650Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates([\"title\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f998306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:39.805741Z",
     "start_time": "2023-10-02T13:10:36.037525Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 7)\n"
     ]
    }
   ],
   "source": [
    "# filtering by language\n",
    "df[\"language\"] = df[\"title\"].apply(lambda x: nlp(x)._.language[\"language\"])\n",
    "df = df[df[\"language\"] == 'en']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac2a3c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:39.818466Z",
     "start_time": "2023-10-02T13:10:39.808434Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium.com                 129\n",
       "towardsdatascience.com      30\n",
       "hackernoon.com               6\n",
       "medium.freecodecamp.org      6\n",
       "Name: link, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking domain names\n",
    "df.link.apply(get_domain).value_counts()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0057e034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:39.823264Z",
     "start_time": "2023-10-02T13:10:39.820505Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# taking only 50 rows (for test)\n",
    "df = df.iloc[:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f04ff7b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:39.829486Z",
     "start_time": "2023-10-02T13:10:39.825560Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ff026",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b512932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:41.010211Z",
     "start_time": "2023-10-02T13:10:39.831823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b18ab34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:42.415471Z",
     "start_time": "2023-10-02T13:10:41.012069Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e09b9063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:42.421042Z",
     "start_time": "2023-10-02T13:10:42.417662Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_tokens(documents): # since we are using dense vectors\n",
    "#     documents = title + \": \" + text\n",
    "    sentences  = [documents]\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    sentence_embeddings = (sentence_embeddings.flatten())\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a379568d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:42.429238Z",
     "start_time": "2023-10-02T13:10:42.424015Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[\"combined_text\"] = df[\"title\"] + \": \" + df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996b3ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0874b3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:52.867075Z",
     "start_time": "2023-10-02T13:10:42.432260Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.81it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df[\"embedding_vectors\"] = df[\"combined_text\"].progress_apply(get_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2468b18a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:52.875529Z",
     "start_time": "2023-10-02T13:10:52.870130Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_json = df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e4029",
   "metadata": {},
   "source": [
    "## elasticSearch (local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8109d71",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### connect to elasticSearch server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "897f8bce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:52.882345Z",
     "start_time": "2023-10-02T13:10:52.878818Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For local\n",
    "# to run elasticsearch server in local:\n",
    "# > cd /<path-to-elasticsearch-folder>/elasticsearch-8.9.2/\n",
    "# > ./bin/elasticsearch  \n",
    "\n",
    "HOST_IP = \"localhost\"\n",
    "PORT = 9200\n",
    "CA_CERT_PATH = \"/Users/arskayal/elasticsearch-8.9.2/config/certs/http_ca.crt\"\n",
    "USERNAME=\"elastic\" # by default\n",
    "PASSWORD=\"e5FmVlxHa568xrO33guk\" # copied from the terminal\n",
    "\n",
    "# es_conn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f6d010c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:52.889976Z",
     "start_time": "2023-10-02T13:10:52.885310Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def connect_elastic():\n",
    "\n",
    "    es_conn = Elasticsearch(\n",
    "        [{\n",
    "            \"host\": HOST_IP,\n",
    "            \"port\": PORT\n",
    "        }],\n",
    "        http_auth=(USERNAME, PASSWORD),\n",
    "        verify_certs=True,\n",
    "        use_ssl=True,\n",
    "        ca_certs=CA_CERT_PATH\n",
    "    )\n",
    "    if es_conn.ping():\n",
    "        print(\"Connected to elasticsearch ... \")\n",
    "    else:\n",
    "        print(\"Elasticsearch connection error ...\")\n",
    "    return es_conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fae7a64e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:52.923976Z",
     "start_time": "2023-10-02T13:10:52.893160Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to elasticsearch ... \n"
     ]
    }
   ],
   "source": [
    "es_conn = connect_elastic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99d27fc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:52.935389Z",
     "start_time": "2023-10-02T13:10:52.926782Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.security-7': {'aliases': {'.security': {'is_hidden': True}}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all existing indices\n",
    "es_conn.indices.get_alias(index=\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c06df7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### create Index and upload data to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbdf3604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:52.940763Z",
     "start_time": "2023-10-02T13:10:52.938049Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index_name = \"medium-article\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e6675b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:52.948064Z",
     "start_time": "2023-10-02T13:10:52.943949Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index_schema = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"embedding_vectors\": {  # column name\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768, # based on the dimension of the model\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"dot_product\"\n",
    "            },\n",
    "            \"title\": {  # column name\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            'text': {  # column name\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            'link': {  # column name\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            'author': {  # column name\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9733786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:52.962953Z",
     "start_time": "2023-10-02T13:10:52.958098Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_index(es_client, index_name):\n",
    "    # for dense vectors: https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html\n",
    "\n",
    "    index_body = index_schema\n",
    "    try:\n",
    "        if not es_client.indices.exists(index_name):\n",
    "            es_client.indices.create(index=index_name, body=index_body)\n",
    "            print(f\"Created Index -> {index_name}\")\n",
    "        else:\n",
    "            print(f\"Index {index_name} exists ...\")\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "\n",
    "\n",
    "def _insert(es_client, index_name, body):\n",
    "#     index_name = \"database300\"\n",
    "    if not es_client.indices.exists(index_name):\n",
    "        create_index(es_client, index_name)\n",
    "\n",
    "    es_client.index(index=index_name, body=body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34face6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:56.775013Z",
     "start_time": "2023-10-02T13:10:52.966534Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Index -> medium-article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 13.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# create and add index\n",
    "for job in tqdm(df_json):\n",
    "    _insert(es_conn, index_name, job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3ca4e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:56.783355Z",
     "start_time": "2023-10-02T13:10:56.777097Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 6, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "# get count of data in server\n",
    "result = es_conn.count(index=index_name)\n",
    "\n",
    "#print the total number of documents in the index\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db7df3",
   "metadata": {},
   "source": [
    "### search using text query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60552739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:56.794583Z",
     "start_time": "2023-10-02T13:10:56.785440Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def semantic_search(es_client, index_name, query_vec, thresh=1.6, top_n=5):\n",
    "    count = es_client.cat.count(index=index_name, params={\"format\": \"json\"})\n",
    "    print('count', count)\n",
    "    if not es_client.indices.exists(index=index_name):\n",
    "        return \"No records found\"\n",
    "\n",
    "    query2 = {\n",
    "        \"size\": top_n,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": []\n",
    "            }\n",
    "        },\n",
    "        \"knn\": {\n",
    "            \"field\": \"embedding_vectors\",\n",
    "            \"query_vector\": query_vec,\n",
    "            \"k\": 10,\n",
    "            \"num_candidates\": 50\n",
    "        }\n",
    "    }\n",
    "    result = es_client.search(index=index_name, body=query2)\n",
    "    total_match = len(result['hits']['hits'])\n",
    "    print(\"Total Matches: \", str(total_match))\n",
    "\n",
    "    output_list = []\n",
    "    counter = 0\n",
    "    if total_match > 0:\n",
    "        for hit in result['hits']['hits']:\n",
    "            counter += 1\n",
    "            output_json = {\n",
    "                           \"title\": hit[\"_source\"][\"title\"],\n",
    "                           \"score\": hit[\"_score\"]}\n",
    "            output_list.append(output_json)\n",
    "\n",
    "    pp.pprint(output_list)\n",
    "    return output_list, count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02e833cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:56.864743Z",
     "start_time": "2023-10-02T13:10:56.797616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count [{'epoch': '1696252256', 'timestamp': '13:10:56', 'count': '38'}]\n",
      "Total Matches:  5\n",
      "[{'score': 1.9171492,\n",
      "  'title': 'Reinforcement Learning from scratch – Insight Data'},\n",
      " {'score': 1.9073708,\n",
      "  'title': 'Machine Learning: how to go from Zero to Hero – freeCodeCamp'},\n",
      " {'score': 1.9070585,\n",
      "  'title': 'Reinventing Social Sciences in the Era of Big Data – I love '\n",
      "           'experiments – Medium'},\n",
      " {'score': 1.9066023,\n",
      "  'title': 'Deep Learning Is Going to Teach Us All the Lesson of Our Lives: '\n",
      "           'Jobs Are for Machines'},\n",
      " {'score': 1.9063506,\n",
      "  'title': 'Every single Machine Learning course on the internet, ranked by '\n",
      "           'your reviews'}]\n"
     ]
    }
   ],
   "source": [
    "query_text = \"renfrcement learning\"\n",
    "token_vector = get_tokens(query_text)\n",
    "output, count = semantic_search(es_conn, index_name, token_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c8d21",
   "metadata": {},
   "source": [
    "## Voice Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d3afc79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:10:56.881780Z",
     "start_time": "2023-10-02T13:10:56.868204Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class VoiceSearch():\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.filename = \"\"\n",
    "        self.root = tk.Tk()\n",
    "        self.recording = None\n",
    "        self.root.resizable(False, False)\n",
    "        self.button = tk.Button(text=\"rec\", font=(\"Ariel\", 50, \"bold\"),\n",
    "                                command=self.click_handler)\n",
    "        self.button.pack()\n",
    "        \n",
    "        self.label = tk.Label(text=\"00:00:00\")\n",
    "        self.label.pack()\n",
    "        \n",
    "        self.root.mainloop()\n",
    "        print(\"exiting!\")\n",
    "        \n",
    "    \n",
    "    def click_handler(self):\n",
    "        if self.recording:\n",
    "            self.recording = False\n",
    "            self.button.config(fg=\"black\")\n",
    "        else:\n",
    "            self.recording = True\n",
    "            self.button.config(fg=\"red\")\n",
    "            threading.Thread(target=self.record).start()\n",
    "            \n",
    "    def record(self):\n",
    "        print(\"Starting session ...\")\n",
    "        audio = pyaudio.PyAudio()\n",
    "        stream = audio.open(format=pyaudio.paInt16, channels=1, rate=44100,\n",
    "                           input=True, frames_per_buffer=1023)\n",
    "    \n",
    "        frames = []\n",
    "        start = time.time()\n",
    "        \n",
    "        while self.recording:\n",
    "            data = stream.read(1024)\n",
    "            frames.append(data)\n",
    "            \n",
    "            passed = time.time() - start\n",
    "            secs = passed % 60\n",
    "            mins = passed // 60\n",
    "            hours = mins // 60\n",
    "            self.label.config(text=f\"{int(hours):02d}:{int(mins):02d}:{int(secs):02d}\")\n",
    "            \n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "        \n",
    "        exists = True\n",
    "        i = 1\n",
    "        while exists:\n",
    "            if os.path.exists(f\"recordings/recording{i}.wav\"):\n",
    "                i+= 1\n",
    "            else:\n",
    "                exists = False\n",
    "                \n",
    "        self.filename = f\"recordings/recording{i}.wav\"\n",
    "        sound_file = wave.open(self.filename, \"wb\")\n",
    "        sound_file.setnchannels(1)\n",
    "        sound_file.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "        sound_file.setframerate(44100)\n",
    "        sound_file.writeframes(b\"\".join(frames))\n",
    "        sound_file.close()\n",
    "        print(f\"audio recorded and saved at {self.filename} \\n\")\n",
    "        \n",
    "        # transcript\n",
    "        audio_file= open(self.filename, \"rb\")\n",
    "        self.transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "        print(f\"Transript: {self.transcript['text']}\\n\")\n",
    "        \n",
    "        # search\n",
    "        token_vector = get_tokens(self.transcript[\"text\"])\n",
    "        semantic_search(self.client, index_name, token_vector)\n",
    "        \n",
    "        print(\"\\n\\n---------------end of session--------------------\\n\\n\")\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adfb4835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:11:18.123509Z",
     "start_time": "2023-10-02T13:10:56.884632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting session ...\n",
      "audio recorded and saved at recordings/recording1.wav \n",
      "\n",
      "Transript: reinforcement learning.\n",
      "\n",
      "count [{'epoch': '1696252274', 'timestamp': '13:11:14', 'count': '50'}]\n",
      "Total Matches:  5\n",
      "[{'score': 1.9167885,\n",
      "  'title': 'Reinforcement Learning from scratch – Insight Data'},\n",
      " {'score': 1.9092228,\n",
      "  'title': 'Machine Learning: how to go from Zero to Hero – freeCodeCamp'},\n",
      " {'score': 1.9084986,\n",
      "  'title': 'From word2vec to doc2vec: an approach driven by Chinese restaurant '\n",
      "           'process'},\n",
      " {'score': 1.9083655,\n",
      "  'title': '6 Tricks I Learned From The OTTO Kaggle Challenge – Christophe '\n",
      "           'Bourguignat – Medium'},\n",
      " {'score': 1.9065192,\n",
      "  'title': 'Machine Learning เรียนอะไร, รู้ไปทําไม – O v e r f i t t e d – '\n",
      "           'Medium'}]\n",
      "\n",
      "\n",
      "---------------end of session--------------------\n",
      "\n",
      "\n",
      "exiting!\n"
     ]
    }
   ],
   "source": [
    "# Once you run this cell, close the newly window to continue to the next step\n",
    "voice_obj = VoiceSearch(es_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43316b8c",
   "metadata": {},
   "source": [
    "## Delete Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "691d03f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T13:11:18.236338Z",
     "start_time": "2023-10-02T13:11:18.126141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_conn.indices.delete(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d96bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
